<chapter id="chapter07">

  <title>Behind the process</title>

  <sect1 id="executable_files">
    <title>Review of executable files</title>

    <para>We know that a program running in memory has two major
    components in <emphasis>code</emphasis> (also commonly known as a
    <emphasis>text</emphasis> for historical reasons) and
    <emphasis>data</emphasis>.  We also know, however, an executable
    does not live its life in memory, but spends most of its life as a
    file on a disk.  This file is in what is referred to as a binary
    format, since the bits and bytes of the file are to be interpreted
    directly by processor hardware.</para>

  </sect1>

  <sect1 id="representing_executables">
    <title>Representing executable files</title>

    <sect2>
      <title>Three Standard Sections</title>

      <para>Any executable file format will need to specify where the
      code and data are in the binary file.</para>

      <para>One additional component we have not mentioned until now
      is storage space of uninitialised global variables.  If we
      declare a variable and give it an initial value this obviously
      needs to be stored in the executable file so that upon execution
      the value is correct.  However many variables are uninitialised
      (or zero) when the program is first executed.  Making space for
      these in the executable and then simply storing zero or NULL
      values in it is a waste of space, needlessly bloating the
      executable file size.  Thus each executable file can define a
      BSS section which simply gives a size for the uninitialised data;
      on program load the extra memory can be allocated (and set to
      zero!).<footnote> <para>BSS probably stands for Block Started by
      Symbol, an assembly command for a old IBM
      computer.</para></footnote></para>
    </sect2>

    <sect2>
      <title>Binary Format</title>

      <para>The executable is created by the toolchain from the source
    code.  This file needs to be in a format explicitly defined such
    that the compiler can create it and the operating system can
    identify it and load into memory, turning it into a running
    process that the operating system can manage.  This
    <emphasis>executable file format</emphasis> can be specific to the
    operating system, as we would not normally expect that a program
    compiled for one system will execute on another (for example, you
    don't expect your Windows programs to run on Linux, or your Linux
    programs to run on OS X).</para>

      <para>However, the common thread between all executable file
    formats is that they include a predefined, standardised header
    which describes how program code and data are stored in the rest
    of the file.  In words, it would generally describe "the program
    code starts 20 bytes into this file, and is 50 kilobytes long.
    The program data follows it and is 20 kilobytes long".</para>

    <para>In recent times one particular format has become the defacto
      standard for executable representation for modern UNIX type
      systems.  It is called the <computeroutput>Executable and Linker
      Format</computeroutput>, or ELF for short; we'll be looking at
      it in more detail soon.</para>

    </sect2>

    <sect2>
      <title>Binary Format History</title>

      <sect3>
	<title>a.out</title>

	<para>ELF was not always the standard; original UNIX systems
      used a file format called
      <computeroutput>a.out</computeroutput>.  We can see the
      vestiges of this if you compile a program without the
      <option>-o</option> option to specify an output file name; the
      executable will be created with a default name of
      <computeroutput>a.out</computeroutput><footnote> <para>In fact,
      <computeroutput>a.out</computeroutput> is the default output
      filename from the <emphasis>linker</emphasis>.  The compiler
      generally uses randomly generated file names as intermediate
      files for assembly and object code.</para></footnote>.</para>

	<para><computeroutput>a.out</computeroutput> is a very simple
	header format that only allows a single data, code and bss
	section.  As you will come to see, this is insufficient for
	modern systems with dynamic libraries.</para>

      </sect3>

      <sect3>
	<title>COFF</title>

	<para>The Common Object File Format, or COFF, was the
	precursor to ELF.  Its header format was more flexible,
	allowing more (but limited) sections in the file.</para>

	<para>COFF also has difficulties with elegant support of
	shared libraries, and ELF was selected as an alternative
	implementation on Linux.</para>

	<para>However, COFF lives on in Microsoft Windows as the
	<computeroutput>Portable Executable</computeroutput> or PE
	format.  PE is to Windows as ELF is to Linux.</para>

      </sect3>

    </sect2>
  </sect1>

  <sect1 id="elf">
    <title>ELF</title>

    <para>ELF is an extremely flexible format for representing binary
    code in a system.  By following the ELF standard you can represent
    a kernel binary just as easily as a normal executable or a system
    library.  The same tools can be used to inspect and operate on all
    ELF files and developers who understand the ELF file format can
    translate their skills to most modern UNIX systems.</para>

    <sect2>
      <title>ELF in depth</title>

      <para>ELF extends on COFF and gives the header sufficient
    flexibility to define an arbitrary number of sections, each with
    its own properties.  This facilitates easier dynamic linking and
    debugging.</para>

      <figure>
	<title>ELF Overview</title>
	<mediaobject>
	  <imageobject>
	    <imagedata fileref="chapter07/figures/elf-overview.eps" format="EPS" />
	  </imageobject>
	  <imageobject role="fo">
	    <imagedata fileref="chapter07/figures/elf-overview.svg"
	    format="SVG" scalefit="1" width="100%"
	    contentdept="100%"/>
	  </imageobject>
	  <imageobject role="html">
	    <imagedata fileref="chapter07/figures/elf-overview.png" format="PNG" />
	  </imageobject>
	  <textobject>
	    <phrase>ELF Overview</phrase>
	  </textobject>
	</mediaobject>
      </figure>

      <sect3>

	<title>ELF File Header</title>

	<para>Overall, the file has a <emphasis>file
	  header</emphasis> which describes the file in general and
	  then has pointers to each of the individual sections that
	  make up the file.</para>

	<example id="elf-header">
	  <title>The ELF Header</title>
	  <programlisting linenumbering="numbered">
              <xi:include href="chapter07/code/elf-header.txt" parse="text"
              xmlns:xi="http://www.w3.org/2001/XInclude" />
            </programlisting>
	</example>

	<para>Above is the description as given in the API
	documentation.  This is the layout of the C structure which
	defines a ELF header.</para>

	<example id="readelf-elf-header">
	  <title>The ELF Header, as shown by <application>readelf</application></title>
	  <programlisting linenumbering="numbered" lang="C">
              <xi:include href="chapter07/code/readelf-elf-header.txt" parse="text"
              xmlns:xi="http://www.w3.org/2001/XInclude" />
            </programlisting>
	</example>

	<para>Above is a more human readable form as present by the
	<application>readelf</application> program, which is part of
	<application>GNU binutils</application>.</para>

	<para>The <computeroutput>e_ident</computeroutput> array is
	the first thing at the start of any ELF file, and always
	starts with a few "magic" bytes.  The first byte is 0x7F and
	then the next three bytes are "ELF".  You can inspect an ELF
	binary to see this for yourself with something like the
	<command>hexdump</command> command.</para>

	    <example id="elf-magic">
	      <title>Inspecting the ELF magic number</title>
	  <programlisting linenumbering="numbered" lang="C">
              <xi:include href="chapter07/code/elf-magic.txt" parse="text"
              xmlns:xi="http://www.w3.org/2001/XInclude" />
            </programlisting>
	    </example>

	<para>Note the 0x7F to start, then the ASCII encoded "ELF"
	string.  Have a look at the standard and see what the rest of
	the array defines and what the values are in a binary.</para>

	<para>Next we have some flags for the type of machine this
	binary is created for.  The first thing we can see is that ELF
	defines different type sized versions, one for 32 bit and one
	for 64 bit versions; here we inspect the 32 bit version.  The
	difference is mostly that on 64 bit machines addresses
	obviously required to be held in 64 bit variables.  We can see
	that the binary has been created for a big endian machine that
	uses 2's complement to represent negative numbers.  Skipping
	down a bit we can see the
	<computeroutput>Machine</computeroutput> tells us this is a
	PowerPC binary.</para>

	<para>The apparently innocuous entry point address seems
	  straight forward enough; this is the address in memory that
	  the program code starts at.</para>

	<para>Beginning C programmers are told that
	  <emphasis>main()</emphasis> is the first program called in
	  your program.  Using the entry point address we can actually
	  verify that it <emphasis>isn't</emphasis>.</para>

	<example id="entry-point">
	  <title>Investigating the entry point</title>
	  <programlisting linenumbering="numbered" lang="C">
              <xi:include href="chapter07/code/entry-point.txt" parse="text"
              xmlns:xi="http://www.w3.org/2001/XInclude" />
            </programlisting>
	</example>

	<para>Above we can see that the entry point is actually a
	  function called <computeroutput>_start</computeroutput>.
	  Our program didn't define this at all, and the leading
	  underscore suggests that it is in a separate
	  <emphasis>namespace</emphasis>.  We examine how a program
	  starts up below.</para>

	<para>After that the header contians pointers to where in the
	file other important parts of the ELF file start, like a table
	of contents.</para>

      </sect3>

      <sect3 id="symbols_and_relocations">
	<title>Symbols and Relocations</title>

	<para>The ELF specification provides for <emphasis>symbol
	tables</emphasis> which are simply mappings of strings
	(symbols) to locations in the file.  Symbols are required for
	linking; for example assigning a value to a variable
	<computeroutput>foo</computeroutput> declared as
	<computeroutput>extern int foo;</computeroutput> would require
	the linker to find the address of
	<computeroutput>foo</computeroutput>, which would involve
	looking up "foo" in the symbol table and finding the
	address.</para>

	<para>Closely related to symbols are
	<emphasis>relocations</emphasis>.  A relocation is simply a
	blank space left to be patched up later.  In the previous
	example, until the address of
	<computeroutput>foo</computeroutput> is known it can not be
	used.  However, on a 32-bit system, we know the
	<emphasis>address</emphasis> of
	<computeroutput>foo</computeroutput> must be a 4-byte value,
	so any time the compiler needs to use that address (to say,
	assign a value) it can simply leave 4-btyes of blank space and
	keep a relocation that essentially says to the linker "place
	the real value of "foo" into the 4 bytes at this address".  As
	mentioned, this requires the symbol "foo" to be resolved.
	<xref linkend="dynamic_relocations"></xref> contains further
	information on relocations.
	</para>

      </sect3>

      <sect3>

	<title>Sections and Segments</title>

	<para>The ELF format specifies two "views" of an ELF file --
	that which is used for linking and that which is used for
	execution.  This affords significant flexibility for systems
	designers.</para>

	<para>We talk about <emphasis>sections</emphasis> in object
	code waiting to be linked into an executable.  One or more
	sections map to a <emphasis>segment</emphasis> in the
	executable.</para>

	<sect4>
	  <title>Segments</title>

	  <para>As we have done before, it is sometimes easier to look
	  at the higher level of abstraction (segments) before
	  inspecting the lower layers.</para>

	  <para>As we mentioned the ELF file has an header that
	  describes the overall layout of the file.  The ELF header
	  actually points to another group of headers called the
	  <emphasis>program headers</emphasis>.  These headers
	  describe to the operating system anything that might be
	  required for it to load the binary into memory and execute
	  it.  Segments are described by program headers, but so are
	  some other things required to get the executable
	  running.</para>

	  <example id="program-header">
	    <title>The Program Header</title>
	  <programlisting linenumbering="numbered" lang="C">
              <xi:include href="chapter07/code/program-header.txt" parse="text"
              xmlns:xi="http://www.w3.org/2001/XInclude" />
            </programlisting>

	  </example>

	  <para>The definition of the program header is seen above.
	  You might have noticed from the ELF header definition above
	  how there were fields
	  <computeroutput>e_phoff</computeroutput>,
	  <computeroutput>e_phnum</computeroutput> and
	  <computeroutput>e_phentsize</computeroutput>; these are
	  simply the offset in the file where the program headers
	  start, how many program headers there are and how big each
	  program header is.  With these three bits of information you
	  can easily find and read the program headers.</para>

	  <para>As we mentioned, program headers more than just
	  segments.  The <computeroutput>p_type</computeroutput> field
	  defines just what the program header is defining.  For
	  example, if this field is
	  <computeroutput>PT_INTERP</computeroutput> the header is
	  defined as meaning a string pointer to an
	  <emphasis>interpreter</emphasis> for the binary file.  We
	  discussed compiled versus interpreted languages previously
	  and made the distinction that a compiler builds a binary
	  which can be run in a stand alone fashion.  Why should it
	  need an interpreter?  As always, the true picture is a
	  little more complicated.  There are several reasons why a
	  modern system wants flexibility when loading executable
	  files, and to do this some information can only be
	  adequately acquired at the actual time the program is set up
	  to run.  We see this in future chapters where we look into
	  dynamic linking.  Consequently some minor changes might need
	  to be made to the binary to allow it to work properly at
	  runtime.  Thus the usual interpreter of a binary file is the
	  <emphasis>dynamic loader</emphasis>, so called because it
	  takes the final steps to complete loading of the executable
	  and prepare the binary image for running.
	  </para>

	  <para>Segments are described with a value of
	  <computeroutput>PT_LOAD</computeroutput> in the
	  <computeroutput>p_type</computeroutput> field.  Each segment
	  is then described by the other fields in the program header.
	  The <computeroutput>p_offset</computeroutput> field tells
	  you how far into the file on disk the data for the segment
	  is.  The <computeroutput>p_vaddr</computeroutput> field
	  tells you what address that data is to live at in virtual
	  memory (<computeroutput>p_addr</computeroutput> describes
	  the physical address, which is only really useful for small
	  embedded systems that do not implement virtual memory).  The
	  two flags <computeroutput>p_filesz</computeroutput> and
	  <computeroutput>p_memsz</computeroutput> work to tell you
	  how big the segment is on disk and how big it should be in
	  memory.  If the memory size is greater than the disk size,
	  then the overlap should be filled with zeros.  In this way
	  you can save considerable space in your binaries by not
	  having to waste space for empty global variables.  Finally
	  <computeroutput>p_flags</computeroutput> indicates the
	  permissions on the segment.  Execute, read and write
	  permissions can be specified in any combiation; for example
	  code segments should be marked as read and execute only,
	  data sections as read and write with no exectue.
	  </para>

	  <para>There are a few other segment types defined in the
	  program headers, they are described more fully in the
	  standards specification (XXX).</para>

	</sect4>

	<sect4>
	  <title>Sections</title>

	  <para>As we have mentioned, sections make up segments.
	  Sections are a way to organise the binary into logical areas
	  to communicate information between the compiler and the
	  linker.  In some special binaries, such as the linux kernel,
	  sections are used in more specific ways.</para>

	  <para>We've seen how segments ultimately come down to a blob
	  of data in a file on disk with some descriptions about where
	  it should be loaded and what permissions it has. (XXX)</para>

	  <para>Sections have a similar header to segments.</para>

	  <example id="section-header">
	    <title>Sections </title>
	  <programlisting linenumbering="numbered" lang="C">
              <xi:include href="chapter07/code/section-header.txt" parse="text"
              xmlns:xi="http://www.w3.org/2001/XInclude" />
            </programlisting>
	  </example>

	  <para>Sections have a few more types defined for the
	  <computeroutput>sh_type</computeroutput> field; for example
	  a section of type
	  <computeroutput>SH_PROGBITS</computeroutput> is defined as a
	  section that hold binary data for use by the program.  Other
	  flags say if this section is a symbol table (used by the
	  linker or debugger for example) or maybe something for the
	  dynamic loader.</para>

	  <para>There are also more attributes, such as the
	  <emphasis>allocate</emphasis> attribute which flags that
	  this section will need memory allocated for it.</para>

	  <para>It is probably best to examine sections through an
	  example of them in use.  Consier the following
	  program.</para>

	  <example id="section">
	    <title>Sections </title>

	  <programlisting linenumbering="numbered" lang="C">
              <xi:include href="chapter07/code/sections.c" parse="text"
              xmlns:xi="http://www.w3.org/2001/XInclude" />
            </programlisting>
	  </example>

	  <example id="section-readelf">
	    <title>Sections readelf output </title>

	  <programlisting linenumbering="numbered">
              <xi:include href="chapter07/code/sections.txt" parse="text"
              xmlns:xi="http://www.w3.org/2001/XInclude" />
            </programlisting>
          </example>

	  <para>Above we have stripped some parts of the
	  <application>readelf</application> output for clarity.  We
	  can analyse each part of our simple program and see what
	  happens to it.</para>

	  <para>Firstly, let us look at the variable
	  <computeroutput>big_big_array</computeroutput>, which as the
	  name suggests is a fairly large global array.  If we skip
	  down to the symbol table we can see that the variable is at
	  location <computeroutput>0x100109cc</computeroutput> which
	  we can correlate to the
	  <computeroutput>.bss</computeroutput> section in the section
	  listing, since it starts just below it at
	  <computeroutput>0x100109c8</computeroutput>.  Note the size,
	  and how it is quite large.  We mentioned that BSS is a
	  standard part of a binary image since it would be silly to
	  require that binary on disk have 10 megabytes of space
	  allocated to it, when all of that space is going to be zero.
	  Note that this section has a type of
	  <computeroutput>NOBITS</computeroutput> meaning that it does
	  not have any bytes on disk.</para>

	  <para>Thus the <computeroutput>.bss</computeroutput> section
	  is defined for global variables whose value should be zero
	  when the program starts.  We have seen how the memory size
	  can be different to the on disk size in our discussion of
	  segments; variables being in the
	  <computeroutput>.bss</computeroutput> section are an
	  indication that they will be given zero value on program
	  start.</para>

	  <para>The <computeroutput>a_string</computeroutput> variable
	  lives in the <computeroutput>.sdata</computeroutput>
	  section, which stands for <emphasis>small data</emphasis>.
	  Small data (and the corresponding
	  <computeroutput>.sbss</computeroutput> section) are sections
	  that can be reached by an offset from some known pointer.
	  This means it is much faster to get to data in the sections
	  as there are no extra lookups and loading of addresses into
	  memory required.  On the other hand, most architectures are
	  limited to the size of immediate values you can add to a
	  register (e.g. saying <computeroutput>r1 = add r2,
	  70;</computeroutput> 70 is an immediate value, as opposed to
	  say, adding two values stored in registers
	  <computeroutput>r1 = add r2,r3</computeroutput>) and can
	  thus only offset a certain "small" distance from an address
	  (XXX).
	  </para>

	  <para>We can also see that our
	  <computeroutput>a_var_with_value</computeroutput> lives in
	  the same place.</para>

	  <para><computeroutput>main</computeroutput> however lives in
	  the <computeroutput>.text</computeroutput> section, as we
	  expect (remeber the name "text" and "code" are used
	  interchanably to refer to a program in memory.</para>

	</sect4>

	<sect4>
	  <title>Sections and Segments together</title>

	  <example id="sections-segments">
	    <title>Sections and Segments</title>

	  <programlisting linenumbering="numbered">
              <xi:include href="chapter07/code/sections-segments.txt" parse="text"
              xmlns:xi="http://www.w3.org/2001/XInclude" />
            </programlisting>

	  </example>

	  <para><computeroutput>readelf</computeroutput> shows us the
	  segments and section mappings in the ELF file for the binary
	  <computeroutput>/bin/ls</computeroutput>. </para>

	  <para>Skipping to the bottom of the output, we can see what
	  sections have been moved into what segments.  So, for
	  example the <computeroutput>.interp</computeroutput> section
	  is placed into an <computeroutput>INTERP</computeroutput>
	  flagged segment.  Notice that readelf tells us it is
	  requesting the interpreter
	  <computeroutput>/lib/ld.so.1</computeroutput>; this is the
	  dynamic linker which is run to prepare the binary for
	  execution.</para>

	  <para>Looking at the two
	  <computeroutput>LOAD</computeroutput> segments we can see
	  the distinction between text and data.  Notice how the first
	  one has only "read" and "execute" permissions, whilst the
	  next one has read, write and execute permissions?  These
	  describe the code (r/w) and data (r/w/e) segments.</para>

	  <para>But data should not need to be executable!  Indeed, on
	  most architectures (for example, the most common x86) the
	  data section will not be marked as having the data section
	  executable.  However, the example output above was taken
	  from a PowerPC machine which has a slightly different
	  programming model (ABI, see below) requiring that the data
	  section be executable <footnote> <para>For those that are
	  curious, the PowerPC ABI calls stubs for functions in
	  dynamic libraries directly in the GOT, rather than having
	  them bounce through a seperate PLT entry.  Thus the
	  processor needs exectute permissions for the GOT section,
	  which you can see is embedded in the data segment.  This
	  should make sense after reading the dynamic linking
	  chapter!</para></footnote>.  Such is the life of a systems
	  programmer, where rules were made to be broken!</para>

	  <para>The other intereseting thing to note is that the file
	  size is the same as the memory size for the code segment,
	  however memory size is greater than the file size for the
	  data segment.  This comes from the BSS section which holds
	  zeroed global variables.</para>
	</sect4>

      </sect3>
    </sect2>

    <sect2 id="elf_debugging">
      <title>Debugging</title>

      <para>Tradionally the primary method of post mortem debugging is
	referred to as the <emphasis>core dump</emphasis>.  The term
	<emphasis>core</emphasis> comes from the original physical
	characteristics of magnetic core memory, which uses the
	orientation of small magnetic rings to store state.
      </para>

      <para>Thus a core dump is simply a complete snapshot of the
	program as it was running at a particular time.  A
	<emphasis>debugger</emphasis> can then be used to examine this
	dump and reconstruct the program state.  <xref
	linkend="coredump_gdb"></xref> shows a sample program that
	writes to a random memory location in order to force a crash.
	At this point the processes will be halted and a dump of the
	current state is recorded.</para>

      <example id="coredump_gdb">
	<title>Example of creating a core dump and using it with <productname>gdb</productname></title>
	  <programlisting linenumbering="numbered" >
              <xi:include href="chapter07/code/core-gdb.txt" parse="text"
              xmlns:xi="http://www.w3.org/2001/XInclude" />
            </programlisting>
      </example>

      <sect3>
	<title>Symbols and Debugging Information</title>

	<para>As the example shows, the debugger
	  <productname>gdb</productname> requires the original
	  executable and the core dump to provide the debugging session.
	  Note that the original executable was built with the
	  <computeroutput>-g</computeroutput> flag, which instructs the
	  compiler to include all <emphasis>debugging
	    information</emphasis>.  Debugging information created by the
	  compiler and is kept in special sections of the ELF file.  It
	  describes in detail things like what register values currently
	  hold which variables used in the code, size of variables,
	  length of arrays, etc.  It is generally in the standard
	  <emphasis>DWARF</emphasis> format (a pun on the homonym ELF).
	</para>

	<para>Including debugging information can make executable
	  files and libraries very large; although this data is not
	  required resident in memory for actually running it can
	  still take up considerable disk space.  Thus the usual
	  process is to <emphasis>strip</emphasis> this information
	  from the ELF file.  While it is possible to arrange for
	  shipping of both stripped and unstripped files, most all
	  current binary distribution methods provide the debugging
	  information in separate files.  The
	  <productname>objcopy</productname> tool can be used to
	  extract the debugging information
	  (<computeroutput>--only-keep-debug</computeroutput>) and
	  then add a link in the original executable to this stripped
	  information
	  (<computeroutput>--add-gnu-debuglink</computeroutput>).
	  After this is done, a special section called
	  <computeroutput>.gnu_debuglink</computeroutput> will be
	  present in the original executable, which contains a hash so
	  that when a debugging sessions starts the debugger can be
	  sure it associates the right debugging information with the
	  right executable.</para>

	  <example id="strip_debug">
	    <title>Example of stripping debugging information into
	    separate files using
	    <productname>objcopy</productname></title>

	  <programlisting linenumbering="numbered">
              <xi:include href="chapter07/code/debuglink.txt" parse="text"
              xmlns:xi="http://www.w3.org/2001/XInclude" />
            </programlisting>
	  </example>

	<para>Symbols take up much less space, but are also targets
	for removal from final output.  Once the individual object
	files of an executable are linked into the single final image
	there is generally no need for most symbols to remain.  As
	discussed in <xref linkend="symbols_and_relocations"></xref>
	symbols are required to fix up relocation entries, but once
	this is done the symbols are not strictly necessary for
	running the final program.  On Linux the GNU toolchain
	<productname>strip</productname> program provides options to
	remove symbols.  Note that some symbols are required to be
	resolved at run-time (for <emphasis>dynamic
	linking</emphasis>, the focus of <xref
	linkend="chapter08"></xref>) but these are put in separate
	<emphasis>dynamic</emphasis> symbol tables so they will not be
	removed and render the final output useless.</para>

      </sect3>

      <sect3>
	<title>Inside coredumps</title>

	<para>A coredump is really just another ELF file; this
	illustrates the flexibility of ELF as a binary format.</para>

	<example id="coredump_internal">
	  <title>Example of using <productname>readelf</productname>
	  and <productname>eu-readelf</productname> to examine a
	  coredump.</title>

	  <programlisting linenumbering="numbered">
              <xi:include href="chapter07/code/core-internal.txt" parse="text"
              xmlns:xi="http://www.w3.org/2001/XInclude" />
            </programlisting>

	</example>

	<para>In <xref linkend="coredump_internal"></xref> we can see
	an examination of the core file produced by <xref
	linkend="coredump_gdb"></xref> using firstly the
	<productname>readelf</productname> tool.  There are no
	sections, relocations or other extraneous information in the
	file that may be required for loading an executable or
	library; it simply consists of a series of program headers
	describing <computeroutput>LOAD</computeroutput> segments.
	These segments are raw data dumps, created by the kernel, of
	the current memory allocations.
	</para>

	<para>The other component of the core dump is the
	<computeroutput>NOTE</computeroutput> sections which contain
	data necessary for debugging but not necessarily captured in
	straight snapshot of the memory allocations.  The
	<productname>eu-readelf</productname> program used in the
	second part of the figure provides a more complete view of the
	data by decoding it.</para>

	<para>The <computeroutput>PRSTATUS</computeroutput> note gives
	a range of interesting information about the process as it was
	running; for example we can see from
	<computeroutput>cursig</computeroutput> that the program
	received a signal 11, or segmentation fault, as we would
	expect.  Along with process number information, it also
	includes a dump of all the current registers.  Given the
	register values, the debugger can reconstruct the stack state
	and hence provide a <emphasis>backtrace</emphasis>; combined
	with the symbol and debugging information from the original
	binary the debugger can show exactly how you reached the
	current point of execution.</para>

	<para>Another interesting output is the current
	  <emphasis>auxiliary vector</emphasis>
	  (<computeroutput>AUXV</computeroutput>), discussed in <xref
	  linkend="auxv"></xref>.  The
	  <computeroutput>386_TLS</computeroutput> describes
	  <emphasis>global descriptor table</emphasis> entries used
	  for the x86 implementation of <emphasis>thread-local
	  storage</emphasis> (see <xref
	  linkend="fast_system_calls"></xref> for more information on
	  use of segmentation, and <xref linkend="threads"></xref> for
	  information on threads<footnote> <para>For a multi-threaded
	  application, there would be duplicate entries for each
	  thread running.  The debugger will understand this, and it
	  is how <productname>gdb</productname> implements the
	  <computeroutput>thread</computeroutput> command to show and
	  switch between threads.</para>
	  </footnote>).
	  </para>

	<para>The kernel creates the core dump file within the bounds
	  of the current <computeroutput>ulimit</computeroutput>
	  settings — since a program using a lot of memory could
	  result in a very large dump, potentially filling up disk and
	  making problems even worse, generally the
	  <computeroutput>ulimit</computeroutput> is set low or even
	  at zero, since most non-developers have little use for a
	  core dump file.  However the core dump remains the single
	  most useful way to debug an unexpected situation in a
	  postmortem fashion.</para>

      </sect3>
    </sect2>

  </sect1>

  <sect1 id="executables">
    <title>ELF Executables</title>

    <para>Executables are of course one of the primary uses of the ELF
      format.  Contained within the <emphasis>binary</emphasis> is
      everything required for the operating system to execute the
      code as intended.</para>

    <para>Since an executable is designed to be run in a process with
    a unique address space (see <xref linkend="chapter05"></xref>) the
    code can make assumptions about where the various parts of the
    program will be loaded in memory.  <xref
    linkend="elf_executable"></xref> shows an example using the
    <productname>readelf</productname> tool to examine the segments of
    an executable file.  We can see the virtual addresses at which the
    <computeroutput>LOAD</computeroutput> segments are required to be
    placed at.  We can further see that one segment is for code
    — it has read and execute permissions only — and one
    is for data, unsurprisingly with read and write permissions, but
    importantly no execute permissions (without execute permissions,
    even if a bug allowed an attacker to introduce arbitrary data the
    pages backing it would not be marked with execute permissions, and
    most processors will hence disallow any execution of code in those
    pages).</para>

    <example id="elf_executable">
      <title>Segments of an executable file</title>
	  <programlisting linenumbering="numbered">
              <xi:include href="chapter07/code/executable.txt" parse="text"
              xmlns:xi="http://www.w3.org/2001/XInclude" />
            </programlisting>
    </example>

    <para>The program segments must be loaded at these addresses; the
    last step of the linker is to resolve most relocations (<xref
    linkend="symbols_and_relocations"></xref>) and patch them with the
    assumed absolute addresses — the data describing the
    relocation is then discarded in the final binary and there is no
    longer a way to find this information.
    </para>

    <para>In reality, executables generally have external dependencies
      on <emphasis>shared libraries</emphasis>, or pieces of common
      code abstracted and shared among the entire system —
      almost all of the confusing parts of <xref
      linkend="elf_executable"></xref> relate to the use of shared
      libraries.  Libraries are discussed in <xref
      linkend="libraries"></xref>, dynamic libraries in <xref
      linkend="chapter08"></xref>.</para>

  </sect1>

  <sect1 id="libraries">
    <title>Libraries</title>

    <para>Developers soon tired of having to write everything from
      scratch, so one of the first inventions of computer science was
      <emphasis>libraries</emphasis>.</para>

    <para>A library is simply a collection of functions which you
      can call from your program.  Obviously a library has many
      advantages, not least of which is that you can save much time by
      reusing work someone else has already done and generally be more
      confident that it has fewer bugs (since probably many other
      people use the libraries too, and you benefit from having them
      finding and fixing bugs).  A library is exactly like an
      executable, except instead of running directly the library
      functions are invoked with parameters from your
      executable.</para>


  <sect2>
    <title>Static Libraries</title>

    <para>The most straight forward way of using a library function is
      to have the object files from the library linked directly into
      your final executable, just as with those you have compiled
      yourself.  When linked like this the library is called a
      <emphasis>static</emphasis> library, because the library will
      remain unchanged unless the program is recompiled.</para>

      <para>This is the most straight forward way of using a library
      as the final result is a simple executable with no
      dependencies.</para>

      <sect3>
	<title>Inside static libraries</title>

	<para>A static library is simply a group of object files.  The
	object files are kept in an <emphasis>archive</emphasis>,
	which leads to their usual <computeroutput>.a</computeroutput>
	suffix extension.  You can think of archives as similar to a
	<command>zip</command> file, but without compression.</para>

	<para>Below we show the creation of basic static library and
	introduce some common tools for working with libraries.</para>

	<example>
	  <title>Creating and using a static library</title>
	  <programlisting linenumbering="numbered">
              <xi:include href="chapter07/code/static.txt" parse="text"
              xmlns:xi="http://www.w3.org/2001/XInclude" />
            </programlisting>
	</example>

	<para>Firstly we compile or library to an object file, just as
	we have seen in the previous chapter.</para>

	<para>Notice that we define the library API in the header
	file.  The API consists of function definitions for the
	functions in the library; this is so that the compiler knows
	what types the functions take when building object files that
	reference the library
	(e.g. <computeroutput>program.c</computeroutput>, which
	<computeroutput>#include</computeroutput>s the header
	file).</para>

	<para>We create the library <application>ar</application>
	(short for "archive") command.  By convention static library
	file names are prefixed with
	<computeroutput>lib</computeroutput> and have the extension
	<computeroutput>.a</computeroutput>.  The
	<computeroutput>c</computeroutput> argument tells the program
	to create the archive, and <computeroutput>a</computeroutput>
	tells archive to add the object files specified into the
	library file.<footnote><para>Archives created with
	<application>ar</application> pop up in a few different places
	around Linux systems other than just creating static
	libraries.  One widely used application is in the
	<computeroutput>.deb</computeroutput> packaging format used
	with Debian, Ubuntu and some other Linux systems is one
	example.  <computeroutput>debs</computeroutput> use archives
	to keep all the application files together in the one package
	file.  Redhat RPM packages use an alternate but similar format
	called <application>cpio</application>.  Of course the
	canonical application for keeping files together is the
	<computeroutput>tar</computeroutput> file, which is a common
	format to distribute source code.</para></footnote></para>

	<para>Next we use the <application>ranlib</application>
	application to make a header in the library with the symbols
	of the object file contents.  This helps the compiler to
	quickly reference symbols; in the case where we just have one
	this step may seem a little redundant; however a large library
	may have thousands of symbols meaning an index can
	significantly speed up finding references.  We inspect this
	new header with the <application>nm</application> application.
	We see the <computeroutput>function</computeroutput> symbol
	for the <computeroutput>function()</computeroutput> function
	at offset zero, as we expect.</para>

	<para>You then specify the library to the compiler with
	<option>-lname</option> where name is the filename of the
	library without the prefix
	<computeroutput>lib</computeroutput>.  We also provide an
	extra search directory for libraries, namely the current
	directory (<option>-L .</option>), since by default the
	current directory is not searched for libraries.</para>

	<para>The final result is a single executable with our new
	library included.</para>

      </sect3>

      <sect3>
	<title>Static Linking Drawbacks</title>

	<para>Static linking is very straight forward, but has a number
      of drawbacks.</para>

	<para>There are two main disadvantages; firstly if the library
      code is updated (to fix a bug, say) you have to recompile your
      program into a new executable and secondly, every program in the
      system that uses that library contains a copy in its
      executable.  This is very inefficient (and a pain if you find a
      bug and have to recompile, as per point one).</para>

	<para>For example, the C library
      (<application>glibc</application>) is included in all programs,
      and provides all the common functions such as
      <computeroutput>printf</computeroutput>.</para>

      </sect3>

    </sect2>

    <sect2>
      <title>Shared Libraries</title>

      <para>Shared libraries are an elegant way around the problems
      posed by a static library.  A shared library is a library that
      is loaded dynamically at runtime for each application that
      requires it.</para>

      <para>The application simply leaves pointers that it will
      require a certain library, and when the function call is made
      the library is loaded into memory and executed.  If the library
      is already loaded for another application, the code can be
      shared between the two, saving considerable resources with
      commonly used libraries.</para>

      <para>This process, called dynamic linking, is one of the more
      intricate parts of a modern operating system.  As such, we
      dedicate the next chapter to investigating the dynamic linking
      process.</para>
    </sect2>


  </sect1>

  <sect1 id="abi">
    <title>ABI's</title>

    <para>An ABI is a term you will hear a lot about when working with
    systems programming.  We have talked extensively about
    <emphasis>API</emphasis>, which are interfaces the programmer sees
    to your code.</para>

    <para>ABI's refer to lower level interfaces which the compiler,
    operating system and, to some extent, processor, must agree on to
    communicate together.  Below we introduce a number of concepts
    which are important to understanding ABI considerations.</para>

    <sect2>
      <title>Byte Order</title>

      <para>Endianess</para>
    </sect2>

    <sect2>
      <title>Calling Conventions</title>

      <sect3>
	<title>Passing parameters</title>
	<para>registers or stack?</para>
      </sect3>

      <sect3>
	<title>Function Descriptors</title>

	<para>On many architectures you must call a function through a
	<emphasis>function descriptor</emphasis>, rather than
	directly.</para>

	<para>For example, on IA64 a function descriptor consists of
	two components; the address of the function (that being a 64
	bit, or 8 byte value) and the address of the <emphasis>global
	pointer</emphasis> (gp).  The ABI specifies that r1 should
	always contain the gp value for a function.  This means that
	when you call a function, it is the
	<computeroutput>callees</computeroutput> job to save their gp
	value, set r1 to be the new value (from the function
	descriptor) and <computeroutput>then</computeroutput> call the
	function.</para>

	<para>This may seem like a strange way to do things, but it
	has very useful practical implications as you will see in the
	next chapter about global offset tables.  On IA64 an
	<computeroutput>add</computeroutput> instruction can only take
	a maximum 22 bit <emphasis>immediate
	value</emphasis><footnote><para>Technically this is because of
	the way IA64 bundles instructions.  Three instructions are put
	into each bundle, and there is only enough room to keep a 22
	bit value to keep the bundle together.</para></footnote>.  An
	immediate value is one that is specified directly, rather than
	in a register (e.g. in <computeroutput>add r1 +
	100</computeroutput> 100 is the immediate value).</para>

	<para>You might recognise 22 bits as being able to represent
	4194304 bytes, or 4MB.  Thus each function can directly offset
	into an area of memory 4MB big without having to take the
	penalty of loading any values into a register.  If the
	compiler, linker and loader all agree on what the global
	pointer is pointing to (as specified in the ABI) performance
	can be improved by less loading.</para>

      </sect3>

    </sect2>

  </sect1>

  <sect1 id="starting_a_process">
    <title>Starting a process</title>

    <para>We mentioned before that simply saying the program starts
    with the <computeroutput>main()</computeroutput> function is not
    quite true.  Below we exaime what happens to a typical dynamically
    linked program when it is loaded and run (statically linked
    programs are similar but different XXX should we go into
    this?).</para>

    <para>Firstly, in response to an
    <computeroutput>exec</computeroutput> system call the kernel
    allocates the structures for a new process and reads the ELF file
    specified from disk.</para>

    <para>We mentioned that ELF has a program interpreter field,
    <computeroutput>PT_INTERP</computeroutput>, which can be set to
    'interpret' the program.  For dynamically linked applications that
    interpreter is the dynamic linker, namely
    <application>ld.so</application>, which allows some of the linking
    process to be done on the fly before the program starts.</para>

    <para>In this case, the kernel <emphasis>also</emphasis> reads in
    the dynamic linker code, and starts the program from the entry
    point address as specified by it.  We examine the role of the
    dynamic linker in depth in the next chapter, but suffice to say it
    does some setup like loading any libraries required by the
    application (as specified in the dynamic section of the binary)
    and then starts execution of the program binary at its entry
    point address (i.e. the <computeroutput>_init</computeroutput>
    function).</para>

    <sect2 id="auxv">
      <title>Kernel communication to programs</title>

      <para>The kernel needs to communicate some things to programs
      when they start up; namely the arguments to the program, the
      current environment variables and a special structure called the
      <computeroutput>Auxiliary Vector</computeroutput> or
      <computeroutput>auxv</computeroutput> (you can request the the
      dynamic linker show you some debugging output of the
      <computeroutput>auxv</computeroutput> by specifying the
      environment value
      <computeroutput>LD_SHOW_AUXV=1</computeroutput>).</para>

      <para>The arguments and environment at fairly straight forward,
      and the various incarnations of the
      <computeroutput>exec</computeroutput> system call allow you to
      specify these for the program.</para>

      <para>The kernel communicates this by putting all the required
      information on the stack for the newly created program to pick
      up.  Thus when the program starts it can use its stack pointer
      to find the all the startup information required.</para>

      <para>The auxiliary vector is a special structure that is for
      passing information directly from the kernel to the newly
      running program.  It contains system specific information that
      may be required, such as the default size of a virtual memory
      page on the system or <emphasis>hardware
      capabilities</emphasis>; that is specific features that the
      kernel has identified the underlying hardware has that userspace
      programs can take advantage of.</para>

      <sect3 id="kernel_library">
	<title>Kernel Library</title>

	<para>We mentioned previously that system calls are slow, and
	modern systems have mechanisms to avoid the overheads of
	calling a trap to the processor.</para>

	<para>In Linux, this is implemented by a neat trick between
	the dynamic loader and the kernel, all communicated with the
	AUXV structure.  The kernel actually adds a small shared
	library into the address space of every newly created process
	which contains a function that makes system calls for you.
	The beauty of this system is that if the underlying hardware
	supports a fast system call mechanism the kernel (being the
	creater of the library) can use it, otherwise it can use the
	old scheme of generating a trap.  This library is named
	<computeroutput>linux-gate.so.1</computeroutput>, so called
	because it is a <emphasis>gateway</emphasis> to the inner
	workings of the kernel.</para>

	<para>When the kernel starts the dynamic linker it adds an
	entry to the auxv called
	<computeroutput>AT_SYSINFO_EHDR</computeroutput>, which is the
	address in memory that the special kernel library lives in.
	When the dynamic linker starts it can look for the
	<computeroutput>AT_SYSINFO_EHDR</computeroutput> pointer, and
	if found load that library for the program.  The program has
	no idea this library exists; this is a private arrangement
	between the dynamic linker and the kernel.</para>

	<para>We mentioned that programmers make system calls
	indirectly through calling functions in the system libraries,
	namely <application>libc</application>.
	<application>libc</application> can check to see if the
	special kernel binary is loaded, and if so use the functions
	within that to make system calls.  As we mentioned, if the
	kernel determines the hardware is capable, this will use the
	fast sytem call method.</para>

      </sect3>

    </sect2>

    <sect2>
      <title>Starting the program</title>

      <para>Once the kernel has loaded the interpreter it passes it to
      the entry point as given in the interpreter file (note will not
      examine how the dynamic linker starts at this stage; see <xref
      linkend="chapter08"></xref> for a full discussion of dynamic
      linking).  The dynamic linker will jump to the entry point
      address as given in the ELF binary.</para>

      <example id="program-startup">
	<title>Disassembly of program startup</title>

	  <programlisting linenumbering="numbered">
              <xi:include href="chapter07/code/startup.txt" parse="text"
              xmlns:xi="http://www.w3.org/2001/XInclude" />
            </programlisting>
      </example>

      <para>Above we investigate the very simplest program.  Using
      <application>readelf</application> we can see that the entry
      point is the <computeroutput>_start</computeroutput> function in
      the binary.  At this point we can see in the disassembly some
      values are pushed onto the stack.  The first value,
      <computeroutput>0x8048400</computeroutput> is the
      <computeroutput>__libc_csu_fini</computeroutput> function;
      <computeroutput>0x8048390</computeroutput> is the
      <computeroutput>__libc_csu_init</computeroutput> and then
      finally <computeroutput>0x8048368</computeroutput>, the
      <computeroutput>main()</computeroutput> function.  After this
      the value <computeroutput>__libc_start_main</computeroutput>
      function is called.</para>

      <para><computeroutput>__libc_start_main</computeroutput> is
      defined in the glibc sources
      <computeroutput>sysdeps/generic/libc-start.c</computeroutput>.
      The file function is quite complicated and hidden between a
      large number of defines, as it needs to be portable across the
      very wide number of systems and architectures that glibc can run
      on.  It does a number of specific things related to setting up
      the C library which the average programmer does not need to
      worry about.  The next point where the library calls back into
      the program is to handle <computeroutput>init</computeroutput>
      code.</para>

      <para><computeroutput>init</computeroutput> and
      <computeroutput>fini</computeroutput> are two special concepts
      that call parts of code in shared libraries that may need to be
      called before the library starts or if the library is unloaded
      respectively.  You can see how this might be useful for library
      programmers to setup variables when the library is started, or
      to clean up at the end.  Originally the functions
      <computeroutput>_init</computeroutput> and
      <computeroutput>_fini</computeroutput> were looked for in the
      library; however this became somewhat limiting as everything was
      required to be in these functions.  Below we will examine just
      how the
      <computeroutput>init</computeroutput>/<computeroutput>fini</computeroutput>
      process works.</para>

      <para>At this stage we can see that the
      <computeroutput>__libc_start_main</computeroutput> function will
      receive quite a few input paramaters on the stack.  Firstly it
      will have access to the program arguments, environment variables
      and auxiliary vector from the kernel.  Then the initalization
      function will have pushed onto the stack addresses for functions
      to handle <computeroutput>init</computeroutput>,
      <computeroutput>fini</computeroutput>, and finally the address
      of the main function itself.</para>

      <para>We need some way to indicate in the source code that a
      function should be called by
      <computeroutput>init</computeroutput> or
      <computeroutput>fini</computeroutput>.  With
      <application>gcc</application> we use
      <emphasis>attributes</emphasis> to label two functions as
      <emphasis>constructors</emphasis> and
      <emphasis>destructors</emphasis> in our main program.  These
      terms are more commonly used with object orientent langauges to
      describe object lifecycles.</para>

      <example id="constructor-destructor">
	<title>Constructors and Destructors</title>
	  <programlisting linenumbering="numbered">
              <xi:include href="chapter07/code/construct-destruct.txt" parse="text"
              xmlns:xi="http://www.w3.org/2001/XInclude" />
            </programlisting>
      </example>

      <para>The last value pushed onto the stack for the
      <computeroutput>__libc_start_main</computeroutput> was the
      initalisation function
      <computeroutput>__libc_csu_init</computeroutput>.  If we follow
      the call chain through from
      <computeroutput>__libc_csu_init</computeroutput> we can see it
      does some setup and then calls the
      <computeroutput>_init</computeroutput> function in the
      executable.  The <computeroutput>_init</computeroutput> function
      eventually calls a function called
      <computeroutput>__do_global_ctors_aux</computeroutput>.  Looking
      at the disassembly of this function we can see that it appears
      to start at address <computeroutput>0x804952c</computeroutput>
      and loop along, reading a value and calling it.  We can see
      that this starting address is in the
      <computeroutput>.ctors</computeroutput> section of the file; if
      we have a look inside this we see that it contains the first
      value <computeroutput>-1</computeroutput>, a function address
      (in big endian format) and the value zero.</para>

      <para>The address in big endian format is
      <computeroutput>0x08048398</computeroutput>, or the address of
      <computeroutput>program_init</computeroutput> function!  So the
      format of the <computeroutput>.ctors</computeroutput> section is
      firstly a -1, and then the address of functions to be called on
      initalisation, and finally a zero to indicate the list is
      complete.  Each entry will be called (in this case we only have
      the one funtion).</para>

      <para>Once <computeroutput>__libc_start_main</computeroutput>
      has completed with the <computeroutput>_init</computeroutput>
      call it <emphasis>finally</emphasis> calls the
      <computeroutput>main()</computeroutput> function!  Remember that
      it had the stack setup initially with the arguments and
      environment pointers from the kernel; this is how main gets its
      <computeroutput>argc, argv[], envp[]</computeroutput> arguments.
      The process now runs and the setup phase is complete.</para>

      <para>A similar process is enacted with the
      <computeroutput>.dtors</computeroutput> for destructors when the
      program exits.
      <computeroutput>__libc_start_main</computeroutput> calls these
      when the <computeroutput>main()</computeroutput> function
      completes.</para>

      <para>As you can see, a lot is done before the program gets to
      start, and even a little after you think it is finished!</para>

    </sect2>

  </sect1>

</chapter>

<!--
Local Variables:
mode: sgml
sgml-parent-document: ("../csbu.sgml" "book" "chapter")
End:
-->
