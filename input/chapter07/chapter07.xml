<?xml version="1.0"?>
<chapter xmlns="http://docbook.org/ns/docbook" xmlns:xi="http://www.w3.org/2001/XInclude" version="5.0" xml:id="chapter07">
  <info>
    <title>Behind the process</title>
  </info>
  <section xml:id="executable_files">
    <info>
      <title>Review of executable files</title>
    </info>
    <para>We know that a program running in memory has two major
    components in <emphasis>code</emphasis> (also commonly known as a
    <emphasis>text</emphasis> for historical reasons) and
    <emphasis>data</emphasis>.  We also know, however, an executable
    does not live its life in memory, but spends most of its life as a
    file on a disk waiting to be loaded a run.  Since a file is, in
    essence, simply a contiguous array of bits, all systems come up
    with methods of organising code and data within files for
    on-demand execution.  This file-format is generally referred to as
    a <emphasis>binary</emphasis> or an
    <emphasis>executable</emphasis>.  The bits and bytes of the file
    are generally in a format ready to be placed in memory and
    interpreted directly by processor hardware.</para>
  </section>
  <section xml:id="representing_executables">
    <info>
      <title>Representing executable files</title>
    </info>
    <section>
      <info>
        <title>Three Standard Sections</title>
      </info>

      <para>At a minimum, any executable file format will need to
      specify where the code and data are in the binary file.  These
      are the two primary sections within an executable file.</para>

      <para>One additional component we have not mentioned until now
      is storage space of uninitialised global variables.  If we
      declare a variable and give it an initial value, this value
      needs to be stored in the executable file so that at program
      start it can be initalised to the correct value.  However many
      variables are uninitialised (or zero) when the program is first
      executed.  Making space for these in the executable and then
      simply storing zero or NULL values is a waste of space,
      needlessly bloating the executable file-size on disk.  Thus most
      binary formats define the concept of a additional
      <computeroutput>BSS</computeroutput> section as a place-holder
      size for zeroed, uninitialised data.  On program load the extra
      memory described by the BSS can be allocated (and set to zero!).
      BSS <emphasis>probably</emphasis> stands for Block Started by
      Symbol, an assembly command for a old IBM computer; the exact
      derivation is probably lost to history.</para>

    </section>
    <section>
      <info>
        <title>Binary Format</title>
      </info>
      <para>The executable is created by the toolchain from the source
    code.  This file needs to be in a format explicitly defined such
    that the compiler can create it and the operating system can
    identify it and load into memory, turning it into a running
    process that the operating system can manage.  This
    <emphasis>executable file format</emphasis> can be specific to the
    operating system, as we would not normally expect that a program
    compiled for one system will execute on another (for example, you
    don't expect your Windows programs to run on Linux, or your Linux
    programs to run on OS X).</para>
      <para>However, the common thread between all executable file
    formats is that they include a predefined, standardised header
    which describes how program code and data are stored in the rest
    of the file.  In words, it would generally describe "the program
    code starts 20 bytes into this file, and is 50 kilobytes long.
    The program data follows it and is 20 kilobytes long".</para>
      <para>In recent times one particular format has become the de facto
      standard for executable representation for modern UNIX type
      systems.  It is called the <computeroutput>Executable and Linker
      Format</computeroutput>, or ELF for short; we'll be looking at
      it in more detail soon.</para>
    </section>
    <section>
      <info>
        <title>Binary Format History</title>
      </info>
      <section>
        <info>
          <title>a.out</title>
        </info>
        <para>ELF was not always the standard; original UNIX systems
      used a file format called
      <computeroutput>a.out</computeroutput>.  We can see the
      vestiges of this if you compile a program without the
      <option>-o</option> option to specify an output file name; the
      executable will be created with a default name of
      <computeroutput>a.out</computeroutput><footnote><para>In fact,
      <computeroutput>a.out</computeroutput> is the default output
      filename from the <emphasis>linker</emphasis>.  The compiler
      generally uses randomly generated file names as intermediate
      files for assembly and object code.</para></footnote>.</para>
        <para><computeroutput>a.out</computeroutput> is a very simple
	header format that only allows a single data, code and BSS
	section.  As you will come to see, this is insufficient for
	modern systems with dynamic libraries.</para>
      </section>
      <section>
        <info>
          <title>COFF</title>
        </info>
        <para>The Common Object File Format, or COFF, was the
        precursor to ELF.  Its header format was more flexible,
        allowing more (but limited) sections in the file.</para>
        <para>COFF also has difficulties with elegant support of
	shared libraries, and ELF was selected as an alternative
	implementation on Linux.</para>
        <para>However, COFF lives on in Microsoft Windows as the
	<computeroutput>Portable Executable</computeroutput> or PE
	format.  PE is to Windows as ELF is to Linux.</para>
      </section>
    </section>
  </section>
  <section xml:id="elf">
    <info>
      <title>ELF</title>
    </info>
    <para>ELF is an extremely flexible format for representing binary
    code in a system.  By following the ELF standard you can represent
    a kernel binary just as easily as a normal executable or a system
    library.  The same tools can be used to inspect and operate on all
    ELF files and developers who understand the ELF file format can
    translate their skills to most modern UNIX systems.</para>

    <para>ELF extends on COFF and gives the header sufficient
    flexibility to define an arbitrary number of sections, each with
    its own properties.  This facilitates easier dynamic linking and
    debugging.</para>

    <figure>
        <info>
          <title>ELF Overview</title>
        </info>
        <mediaobject>
          <imageobject>
            <imagedata fileref="chapter07/figures/elf-overview.eps" format="EPS"/>
          </imageobject>
          <imageobject >
            <imagedata fileref="figures/elf-overview.svg" format="SVG" />
          </imageobject>
          <imageobject role="html">
            <imagedata fileref="chapter07/figures/elf-overview.png" format="PNG"/>
          </imageobject>
          <textobject>
            <phrase>ELF Overview</phrase>
          </textobject>
        </mediaobject>
      </figure>
      <section>
        <info>
          <title>ELF File Header</title>
        </info>
        <para>Overall, the file has a <emphasis>file header</emphasis>
        which describes the file in general and then has pointers to
        each of the individual sections that make up the file.  <xref
        linkend="elf-header" /> shows the description as given in the
        API documentation for ELF32 (the 32-bit form of ELF).  This is
        the layout of the C structure which defines a ELF
        header.</para>

        <example xml:id="elf-header">
          <info>
            <title>The ELF Header</title>
          </info>
          <programlisting linenumbering="numbered"><xi:include href="code/elf-header.txt" parse="text"/></programlisting>
        </example>
        <example xml:id="readelf-elf-header">
          <info>
            <title>The ELF Header, as shown by <application>readelf</application></title>
          </info>
          <programlisting linenumbering="numbered"><xi:include href="code/readelf-elf-header.txt" parse="text"/></programlisting>
        </example>
        <para><xref linkend="readelf-elf-header" /> shows a human
        readable form as present by the
        <application>readelf</application> program, which is part of
        <application>GNU binutils</application>.</para>
        <para>The <computeroutput>e_ident</computeroutput> array is
        the first thing at the start of any ELF file, and always
        starts with a few "magic" bytes.  The first byte is 0x7F and
        then the next three bytes are "ELF".  You can inspect an ELF
        binary to see this for yourself with something like the
        <command>hexdump</command> command.</para>
        <example xml:id="elf-magic">
          <info>
            <title>Inspecting the ELF magic number</title>
          </info>
          <programlisting linenumbering="numbered"><xi:include href="code/elf-magic.txt" parse="text"/></programlisting>
        </example>
        <para>Note the 0x7F to start, then the ASCII encoded "ELF"
        string.  Have a look at the standard and see what the rest of
        the array defines and what the values are in a binary.</para>
        <para>Next we have some flags for the type of machine this
        binary is created for.  The first thing we can see is that ELF
        defines different type sized versions, one for 32 bit and one
        for 64 bit versions; here we inspect the 32 bit version.  The
        difference is mostly that on 64 bit machines addresses
        obviously required to be held in 64 bit variables.  We can see
        that the binary has been created for a big endian machine that
        uses 2's complement to represent negative numbers.  Skipping
        down a bit we can see the
        <computeroutput>Machine</computeroutput> tells us this is a
        PowerPC binary.</para>
        <para>The apparently innocuous entry point address seems
        straight forward enough; this is the address in memory that
        the program code starts at.  Beginning C programmers are told
        that <emphasis>main()</emphasis> is the first program called
        in your program.  Using the entry point address we can
        actually verify that it <emphasis>isn't</emphasis>.</para>
        <example xml:id="entry-point">
          <info>
            <title>Investigating the entry point</title>
          </info>
          <programlisting linenumbering="numbered"><xi:include href="code/entry-point.txt" parse="text"/></programlisting>
        </example>
        <para>In <xref linkend="entry-point" /> we can see that the
        entry point is actually a function called
        <computeroutput>_start</computeroutput>.  Our program didn't
        define this at all, and the leading underscore suggests that
        it is in a separate <emphasis>namespace</emphasis>.  We
        examine how a program starts up in detail in <xref
        linkend="startup" />.</para>
        <para>After that the header contains pointers to where in the
        file other important parts of the ELF file start, like a table
        of contents.</para>
      </section>
      <section xml:id="symbols_and_relocations">
        <info>
          <title>Symbols and Relocations</title>
        </info>
        <para>The ELF specification provides for <emphasis>symbol
        tables</emphasis> which are simply mappings of strings
        (symbols) to locations in the file.  Symbols are required for
        linking; for example assigning a value to a variable
        <computeroutput>foo</computeroutput> declared as
        <computeroutput>extern int foo;</computeroutput> would require
        the linker to find the address of
        <computeroutput>foo</computeroutput>, which would involve
        looking up "foo" in the symbol table and finding the
        address.</para>
        <para>Closely related to symbols are
        <emphasis>relocations</emphasis>.  A relocation is simply a
        blank space left to be patched up later.  In the previous
        example, until the address of
        <computeroutput>foo</computeroutput> is known it can not be
        used.  However, on a 32-bit system, we know the
        <emphasis>address</emphasis> of
        <computeroutput>foo</computeroutput> must be a 4-byte value,
        so any time the compiler needs to use that address (to say,
        assign a value) it can simply leave 4-bytes of blank space and
        keep a relocation that essentially says to the linker "place
        the real value of "foo" into the 4 bytes at this address".  As
        mentioned, this requires the symbol "foo" to be resolved.
        <xref linkend="dynamic_relocations"/> contains further
        information on relocations.
	</para>
      </section>
      <section>
        <info>
          <title>Sections and Segments</title>
        </info>
        <para>The ELF format specifies two "views" of an ELF file —
        that which is used for linking and that which is used for
        execution.  This affords significant flexibility for systems
        designers.</para>
        <para>We talk about <emphasis>sections</emphasis> in object
        code waiting to be linked into an executable.  One or more
        sections map to a <emphasis>segment</emphasis> in the
        executable.</para>
        <section>
          <info>
            <title>Segments</title>
          </info>
          <para>As we have done before, it is sometimes easier to look
          at the higher level of abstraction (segments) before
          inspecting the lower layers.</para>
          <para>As we mentioned the ELF file has an header that
          describes the overall layout of the file.  The ELF header
          actually points to another group of headers called the
          <emphasis>program headers</emphasis>.  These headers
          describe to the operating system anything that might be
          required for it to load the binary into memory and execute
          it.  Segments are described by program headers, but so are
          some other things required to get the executable
          running.</para>
          <example xml:id="program-header">
            <info>
              <title>The Program Header</title>
            </info>
            <programlisting linenumbering="numbered"><xi:include href="code/program-header.txt" parse="text"/></programlisting>
          </example>
          <para>The definition of the program header is seen in <xref
          linkend="program-header" />.  You might have noticed from
          the ELF header definition above how there were fields
          <computeroutput>e_phoff</computeroutput>,
          <computeroutput>e_phnum</computeroutput> and
          <computeroutput>e_phentsize</computeroutput>; these are
          simply the offset in the file where the program headers
          start, how many program headers there are and how big each
          program header is.  With these three bits of information you
          can easily find and read the program headers.</para>
          <para>Program headers more than just segments.  The
          <computeroutput>p_type</computeroutput> field defines just
          what the program header is defining.  For example, if this
          field is <computeroutput>PT_INTERP</computeroutput> the
          header is defined as meaning a string pointer to an
          <emphasis>interpreter</emphasis> for the binary file.  We
          discussed compiled versus interpreted languages previously
          and made the distinction that a compiler builds a binary
          which can be run in a stand alone fashion.  Why should it
          need an interpreter?  As always, the true picture is a
          little more complicated.  There are several reasons why a
          modern system wants flexibility when loading executable
          files, and to do this some information can only be
          adequately acquired at the actual time the program is set up
          to run.  We see this in future chapters where we look into
          dynamic linking.  Consequently some minor changes might need
          to be made to the binary to allow it to work properly at
          runtime.  Thus the usual interpreter of a binary file is the
          <emphasis>dynamic loader</emphasis>, so called because it
          takes the final steps to complete loading of the executable
          and prepare the binary image for running.
	  </para>
          <para>Segments are described with a value of
          <computeroutput>PT_LOAD</computeroutput> in the
          <computeroutput>p_type</computeroutput> field.  Each segment
          is then described by the other fields in the program header.
          The <computeroutput>p_offset</computeroutput> field tells
          you how far into the file on disk the data for the segment
          is.  The <computeroutput>p_vaddr</computeroutput> field
          tells you what address that data is to live at in virtual
          memory (<computeroutput>p_addr</computeroutput> describes
          the physical address, which is only really useful for small
          embedded systems that do not implement virtual memory).  The
          two flags <computeroutput>p_filesz</computeroutput> and
          <computeroutput>p_memsz</computeroutput> work to tell you
          how big the segment is on disk and how big it should be in
          memory.  If the memory size is greater than the disk size,
          then the overlap should be filled with zeros.  In this way
          you can save considerable space in your binaries by not
          having to waste space for empty global variables.  Finally
          <computeroutput>p_flags</computeroutput> indicates the
          permissions on the segment.  Execute, read and write
          permissions can be specified in any combination; for example
          code segments should be marked as read and execute only,
          data sections as read and write with no execute.
	  </para>
          <para>There are a few other segment types defined in the
          program headers, they are described more fully in the
          standards specification.</para>
        </section>
        <section xml:id="sections">
          <info>
            <title>Sections</title>
          </info>
          <para>As we have mentioned, sections make up segments.
          Sections are a way to organise the binary into logical areas
          to communicate information between the compiler and the
          linker.  In some special binaries, such as the Linux kernel,
          sections are used in more specific ways (see <xref
          linkend="extra_sections" />).</para>
          <para>We've seen how segments ultimately come down to a blob
          of data in a file on disk with some descriptions about where
          it should be loaded and what permissions it has.  Sections
          have a similar header to segments, as shown in <xref
          linkend="section-header" />.</para>
          <example xml:id="section-header">
            <info>
              <title>Sections </title>
            </info>
            <programlisting linenumbering="numbered"><xi:include href="code/section-header.txt" parse="text"/></programlisting>
          </example>
          <para>Sections have a few more types defined for the
          <computeroutput>sh_type</computeroutput> field; for example
          a section of type
          <computeroutput>SH_PROGBITS</computeroutput> is defined as a
          section that hold binary data for use by the program.  Other
          flags say if this section is a symbol table (used by the
          linker or debugger for example) or maybe something for the
          dynamic loader.  There are also more attributes, such as the
          <emphasis>allocate</emphasis> attribute which flags that
          this section will need memory allocated for it.</para>
          <para>Below we will examine the program listed in <xref
          linkend="section" />.</para>
          <example xml:id="section">
            <info>
              <title>Sections </title>
            </info>
            <programlisting linenumbering="numbered" language="c"><xi:include href="code/sections.c" parse="text"/></programlisting>
          </example>
          <para><xref linkend="section-readelf" /> shows the output of
          <application>readelf</application> with some parts stripped
          clarity.  Using this output we can analyse each part of our
          simple program and see where it ends up in the final output
          binary.</para>
          <example xml:id="section-readelf">
            <info>
              <title>Sections readelf output </title>
            </info>
            <programlisting linenumbering="numbered"><xi:include href="code/sections.txt" parse="text"/></programlisting>
          </example>
          <para>Firstly, let us look at the variable
          <computeroutput>big_big_array</computeroutput>, which as the
          name suggests is a fairly large global array.  If we skip
          down to the symbol table we can see that the variable is at
          location <computeroutput>0x100109cc</computeroutput> which
          we can correlate to the
          <computeroutput>.bss</computeroutput> section in the section
          listing, since it starts just below it at
          <computeroutput>0x100109c8</computeroutput>.  Note the size,
          and how it is quite large.  We mentioned that BSS is a
          standard part of a binary image since it would be silly to
          require that binary on disk have 10 megabytes of space
          allocated to it, when all of that space is going to be zero.
          Note that this section has a type of
          <computeroutput>NOBITS</computeroutput> meaning that it does
          not have any bytes on disk.</para>
          <para>Thus the <computeroutput>.bss</computeroutput> section
          is defined for global variables whose value should be zero
          when the program starts.  We have seen how the memory size
          can be different to the on disk size in our discussion of
          segments; variables being in the
          <computeroutput>.bss</computeroutput> section are an
          indication that they will be given zero value on program
          start.</para>
          <para>The <computeroutput>a_string</computeroutput> variable
          lives in the <computeroutput>.sdata</computeroutput>
          section, which stands for <emphasis>small data</emphasis>.
          Small data (and the corresponding
          <computeroutput>.sbss</computeroutput> section) are sections
          available on some architectures where data can be reached by
          an offset from some known pointer.  This means a fixed-value
          can be added to the base-address, making it faster to get to
          data in the sections as there are no extra lookups and
          loading of addresses into memory required.  Most
          architectures are limited to the size of immediate values
          you can add to a register (e.g. if performing the
          instruction <computeroutput>r1 = add r2,
          70;</computeroutput>, 70 is an <emphasis>immediate
          value</emphasis>, as opposed to say, adding two values
          stored in registers <computeroutput>r1 = add
          r2,r3</computeroutput>) and can thus only offset a certain
          "small" distance from an address.  We can also see that our
          <computeroutput>a_var_with_value</computeroutput> lives in
          the same place.</para>
          <para><computeroutput>main</computeroutput> however lives in
          the <computeroutput>.text</computeroutput> section, as we
          expect (remember the name "text" and "code" are used
          interchangeably to refer to a program in memory.</para>
        </section>
        <section>
          <info>
            <title>Sections and Segments together</title>
          </info>
          <example xml:id="sections-segments">
            <info>
              <title>Sections and Segments</title>
            </info>
            <programlisting linenumbering="numbered"><xi:include href="code/sections-segments.txt" parse="text"/></programlisting>
          </example>
          <para><xref linkend="sections-segments" /> shows how
          <computeroutput>readelf</computeroutput> shows us the
          segments and section mappings in the ELF file for the binary
          <computeroutput>/bin/ls</computeroutput>. </para>
          <para>Skipping to the bottom of the output, we can see what
          sections have been moved into what segments.  So, for
          example the <computeroutput>.interp</computeroutput> section
          is placed into an <computeroutput>INTERP</computeroutput>
          flagged segment.  Notice that readelf tells us it is
          requesting the interpreter
          <computeroutput>/lib/ld.so.1</computeroutput>; this is the
          dynamic linker which is run to prepare the binary for
          execution.</para>
          <para>Looking at the two
          <computeroutput>LOAD</computeroutput> segments we can see
          the distinction between text and data.  Notice how the first
          one has only "read" and "execute" permissions, whilst the
          next one has read, write and execute permissions?  These
          describe the code (r/w) and data (r/w/e) segments.</para>
          <para>But data should not need to be executable!  Indeed, on
          most architectures (for example, the most common x86) the
          data section will not be marked as having the data section
          executable.  However, the example output above was taken
          from a PowerPC machine which has a slightly different
          programming model (ABI, see below) requiring that the data
          section be executable <footnote><para>For those that are
          curious, the PowerPC ABI calls stubs for functions in
          dynamic libraries directly in the GOT, rather than having
          them bounce through a separate PLT entry.  Thus the
          processor needs execute permissions for the GOT section,
          which you can see is embedded in the data segment.  This
          should make sense after reading the dynamic linking
          chapter!</para></footnote>.  Such is the life of a systems
          programmer, where rules were made to be broken!</para>
          <para>The other interesting thing to note is that the file
          size is the same as the memory size for the code segment,
          however memory size is greater than the file size for the
          data segment.  This comes from the BSS section which holds
          zeroed global variables.</para>
        </section>
      </section>
    </section>

  <section xml:id="executables">
    <info>
      <title>ELF Executables</title>
    </info>
    <para>Executables are of course one of the primary uses of the ELF
      format.  Contained within the <emphasis>binary</emphasis> is
      everything required for the operating system to execute the
      code as intended.</para>
    <para>Since an executable is designed to be run in a process with
    a unique address space (see <xref linkend="chapter05"/>) the
    code can make assumptions about where the various parts of the
    program will be loaded in memory.  <xref linkend="elf_executable"/> shows an example using the
    <productname>readelf</productname> tool to examine the segments of
    an executable file.  We can see the virtual addresses at which the
    <computeroutput>LOAD</computeroutput> segments are required to be
    placed at.  We can further see that one segment is for code
    &#x2014; it has read and execute permissions only &#x2014; and one
    is for data, unsurprisingly with read and write permissions, but
    importantly no execute permissions (without execute permissions,
    even if a bug allowed an attacker to introduce arbitrary data the
    pages backing it would not be marked with execute permissions, and
    most processors will hence disallow any execution of code in those
    pages).</para>
    <example xml:id="elf_executable">
      <info>
        <title>Segments of an executable file</title>
      </info>
      <programlisting linenumbering="numbered"><xi:include href="code/executable.txt" parse="text"/></programlisting>
    </example>
    <para>The program segments must be loaded at these addresses; the
    last step of the linker is to resolve most relocations (<xref linkend="symbols_and_relocations"/>) and patch them with the
    assumed absolute addresses &#x2014; the data describing the
    relocation is then discarded in the final binary and there is no
    longer a way to find this information.
    </para>
    <para>In reality, executables generally have external dependencies
      on <emphasis>shared libraries</emphasis>, or pieces of common
      code abstracted and shared among the entire system &#x2014;
      almost all of the confusing parts of <xref linkend="elf_executable"/> relate to the use of shared
      libraries.  Libraries are discussed in <xref linkend="libraries"/>, dynamic libraries in <xref linkend="chapter08"/>.</para>
  </section>
  <section xml:id="libraries">
    <info>
      <title>Libraries</title>
    </info>
    <para>Developers soon tired of having to write everything from
      scratch, so one of the first inventions of computer science was
      <emphasis>libraries</emphasis>.</para>
    <para>A library is simply a collection of functions which you
      can call from your program.  Obviously a library has many
      advantages, not least of which is that you can save much time by
      reusing work someone else has already done and generally be more
      confident that it has fewer bugs (since probably many other
      people use the libraries too, and you benefit from having them
      finding and fixing bugs).  A library is exactly like an
      executable, except instead of running directly the library
      functions are invoked with parameters from your
      executable.</para>
    <section>
      <info>
        <title>Static Libraries</title>
      </info>
      <para>The most straight forward way of using a library function is
      to have the object files from the library linked directly into
      your final executable, just as with those you have compiled
      yourself.  When linked like this the library is called a
      <emphasis>static</emphasis> library, because the library will
      remain unchanged unless the program is recompiled.</para>
      <para>This is the most straight forward way of using a library
      as the final result is a simple executable with no
      dependencies.</para>
      <section>
        <info>
          <title>Inside static libraries</title>
        </info>
        <para>A static library is simply a group of object files.  The
	object files are kept in an <emphasis>archive</emphasis>,
	which leads to their usual <computeroutput>.a</computeroutput>
	suffix extension.  You can think of archives as similar to a
	<command>zip</command> file, but without compression.</para>
        <para>Below we show the creation of basic static library and
	introduce some common tools for working with libraries.</para>
        <example>
          <info>
            <title>Creating and using a static library</title>
          </info>
          <programlisting linenumbering="numbered"><xi:include href="code/static.txt" parse="text"/></programlisting>
        </example>
        <para>Firstly we compile our library to an object file, just
        as we have seen in the previous chapter.</para>
        <para>Notice that we define the library API in the header
	file.  The API consists of function definitions for the
	functions in the library; this is so that the compiler knows
	what types the functions take when building object files that
	reference the library
	(e.g. <computeroutput>program.c</computeroutput>, which
	<computeroutput>#include</computeroutput>s the header
	file).</para>
        <para>We create the library using <application>ar</application>
	(short for "archive") command.  By convention static library
	file names are prefixed with
	<computeroutput>lib</computeroutput> and have the extension
	<computeroutput>.a</computeroutput>.  The
	<computeroutput>c</computeroutput> argument tells the program
	to create the archive, and <computeroutput>r</computeroutput>
	tells archive to add the object files specified into the
	library file.<footnote><para>Archives created with
	<application>ar</application> pop up in a few different places
	around Linux systems other than just creating static
	libraries.  One widely used application is in the
	<computeroutput>.deb</computeroutput> packaging format used
	with Debian, Ubuntu and some other Linux systems is one
	example.  <computeroutput>debs</computeroutput> use archives
	to keep all the application files together in the one package
	file.  RedHat RPM packages use an alternate but similar format
	called <application>cpio</application>.  Of course the
	canonical application for keeping files together is the
	<computeroutput>tar</computeroutput> file, which is a common
	format to distribute source code.</para></footnote></para>
        <para>Next we use the <application>ranlib</application>
	application to make a header in the library with the symbols
	of the object file contents.  This helps the compiler to
	quickly reference symbols; in the case where we just have one
	this step may seem a little redundant; however a large library
	may have thousands of symbols meaning an index can
	significantly speed up finding references.  We inspect this
	new header with the <application>nm</application> application.
	We see the <computeroutput>function</computeroutput> symbol
	for the <computeroutput>function()</computeroutput> function
	at offset zero, as we expect.</para>
        <para>You then specify the library to the compiler with
	<option>-lname</option> where name is the filename of the
	library without the prefix
	<computeroutput>lib</computeroutput>.  We also provide an
	extra search directory for libraries, namely the current
	directory (<option>-L .</option>), since by default the
	current directory is not searched for libraries.</para>
        <para>The final result is a single executable with our new
	library included.</para>
      </section>
      <section>
        <info>
          <title>Static Linking Drawbacks</title>
        </info>
        <para>Static linking is very straight forward, but has a number
      of drawbacks.</para>
        <para>There are two main disadvantages; firstly if the library
        code is updated (to fix a bug, say) you have to recompile your
        program into a new executable and secondly, every program in
        the system that uses that library contains a copy in its
        executable.  This is very inefficient (and a pain if you find
        a bug and have to recompile, as per point one).</para>
        <para>For example, the C library
      (<application>glibc</application>) is included in all programs,
      and provides all the common functions such as
      <computeroutput>printf</computeroutput>.</para>
      </section>
    </section>
    <section>
      <info>
        <title>Shared Libraries</title>
      </info>
      <para>Shared libraries are an elegant way around the problems
      posed by a static library.  A shared library is a library that
      is loaded dynamically at runtime for each application that
      requires it.</para>
      <para>The application simply leaves pointers that it will
      require a certain library, and when the function call is made
      the library is loaded into memory and executed.  If the library
      is already loaded for another application, the code can be
      shared between the two, saving considerable resources with
      commonly used libraries.</para>
      <para>This process, called dynamic linking, is one of the more
      intricate parts of a modern operating system.  As such, we
      dedicate the next chapter to investigating the dynamic linking
      process.</para>
    </section>
  </section>

  <section xml:id="elf-sections-others">
    <info>
      <title>Extending ELF concepts</title>
    </info>
    <section xml:id="elf_debugging">
      <info>
        <title>Debugging</title>
      </info>
      <para>Traditionally the primary method of post mortem debugging
      is referred to as the <emphasis>core dump</emphasis>.  The term
      <emphasis>core</emphasis> comes from the original physical
      characteristics of magnetic core memory, which uses the
      orientation of small magnetic rings to store state.
      </para>
      <para>Thus a core dump is simply a complete snapshot of the
      program as it was running at a particular time.  A
      <emphasis>debugger</emphasis> can then be used to examine this
      dump and reconstruct the program state.  <xref
      linkend="coredump_gdb"/> shows a sample program that writes to a
      random memory location in order to force a crash.  At this point
      the processes will be halted and a dump of the current state is
      recorded.</para>
      <example xml:id="coredump_gdb">
        <info>
          <title>Example of creating a core dump and using it with <productname>gdb</productname></title>
        </info>
        <programlisting linenumbering="numbered"><xi:include href="code/core-gdb.txt" parse="text"/></programlisting>
      </example>

      <para>Thus a core-dump is just another ELF file with a range of
      sections understood to the debugger to represent parts of the
      running program.</para>

      <section>
        <info>
          <title>Symbols and Debugging Information</title>
        </info>
        <para>As <xref linkend="coredump_gdb" /> shows, the debugger
        <productname>gdb</productname> requires the original
        executable and the core dump to reconstruct the environment
        for the debugging session.  Note that the original executable
        was built with the <computeroutput>-g</computeroutput> flag,
        which instructs the compiler to include all
        <emphasis>debugging information</emphasis>.  This extra
        debugging information is kept in special sections of the ELF
        file.  It describes in detail things like what register values
        currently hold which variables used in the code, size of
        variables, length of arrays, etc.  It is generally in the
        standard <emphasis>DWARF</emphasis> format (a pun on the
        almost-synonym ELF).
        </para>
        <para>Including debugging information can make executable
        files and libraries very large; although this data is not
        required resident in memory for actually running it can still
        take up considerable disk space.  Thus the usual process is to
        <emphasis>strip</emphasis> this information from the ELF file.
        While it is possible to arrange for shipping of both stripped
        and unstripped files, most all current binary distribution
        methods provide the debugging information in separate files.
        The <productname>objcopy</productname> tool can be used to
        extract the debugging information
        (<computeroutput>--only-keep-debug</computeroutput>) and then
        add a link in the original executable to this stripped
        information
        (<computeroutput>--add-gnu-debuglink</computeroutput>).  After
        this is done, a special section called
        <computeroutput>.gnu_debuglink</computeroutput> will be
        present in the original executable, which contains a hash so
        that when a debugging sessions starts the debugger can be sure
        it associates the right debugging information with the right
        executable.</para>
        <example xml:id="strip_debug">
          <info>
            <title>Example of stripping debugging information into
            separate files using
            <productname>objcopy</productname></title>
          </info>
          <programlisting linenumbering="numbered"><xi:include href="code/debuglink.txt" parse="text"/></programlisting>
        </example>
        <para>Symbols take up much less space, but are also targets
        for removal from final output.  Once the individual object
        files of an executable are linked into the single final image
        there is generally no need for most symbols to remain.  As
        discussed in <xref linkend="symbols_and_relocations"/> symbols
        are required to fix up relocation entries, but once this is
        done the symbols are not strictly necessary for running the
        final program.  On Linux the GNU toolchain
        <productname>strip</productname> program provides options to
        remove symbols.  Note that some symbols are required to be
        resolved at run-time (for <emphasis>dynamic
        linking</emphasis>, the focus of <xref linkend="chapter08"/>)
        but these are put in separate <emphasis>dynamic</emphasis>
        symbol tables so they will not be removed and render the final
        output useless.</para>
      </section>
      <section>
        <info>
          <title>Inside coredumps</title>
        </info>
        <para>A coredump is really just another ELF file; this
        illustrates the flexibility of ELF as a binary format.</para>
        <example xml:id="coredump_internal">
          <info>
            <title>Example of using <productname>readelf</productname>
            and <productname>eu-readelf</productname> to examine a
            coredump.</title>
          </info>
          <programlisting linenumbering="numbered"><xi:include href="code/core-internal.txt" parse="text"/></programlisting>
        </example>
        <para>In <xref linkend="coredump_internal"/> we can see an
        examination of the core file produced by <xref
        linkend="coredump_gdb"/> using firstly the
        <productname>readelf</productname> tool.  There are no
        sections, relocations or other extraneous information in the
        file that may be required for loading an executable or
        library; it simply consists of a series of program headers
        describing <computeroutput>LOAD</computeroutput> segments.
        These segments are raw data dumps, created by the kernel, of
        the current memory allocations.
	</para>
        <para>The other component of the core dump is the
        <computeroutput>NOTE</computeroutput> sections which contain
        data necessary for debugging but not necessarily captured in
        straight snapshot of the memory allocations.  The
        <productname>eu-readelf</productname> program used in the
        second part of the figure provides a more complete view of the
        data by decoding it.</para>
        <para>The <computeroutput>PRSTATUS</computeroutput> note gives
        a range of interesting information about the process as it was
        running; for example we can see from
        <computeroutput>cursig</computeroutput> that the program
        received a signal 11, or segmentation fault, as we would
        expect.  Along with process number information, it also
        includes a dump of all the current registers.  Given the
        register values, the debugger can reconstruct the stack state
        and hence provide a <emphasis>backtrace</emphasis>; combined
        with the symbol and debugging information from the original
        binary the debugger can show exactly how you reached the
        current point of execution.</para>
        <para>Another interesting output is the current
        <emphasis>auxiliary vector</emphasis>
        (<computeroutput>AUXV</computeroutput>), discussed in <xref
        linkend="auxv"/>.  The
        <computeroutput>386_TLS</computeroutput> describes
        <emphasis>global descriptor table</emphasis> entries used for
        the x86 implementation of <emphasis>thread-local
        storage</emphasis> (see <xref linkend="fast_system_calls"/>
        for more information on use of segmentation, and <xref
        linkend="threads"/> for information on
        threads<footnote><para>For a multi-threaded application, there
        would be duplicate entries for each thread running.  The
        debugger will understand this, and it is how
        <productname>gdb</productname> implements the
        <computeroutput>thread</computeroutput> command to show and
        switch between threads.</para></footnote>).
	  </para>
        <para>The kernel creates the core dump file within the bounds
        of the current <computeroutput>ulimit</computeroutput>
        settings &#x2014; since a program using a lot of memory could
        result in a very large dump, potentially filling up disk and
        making problems even worse, generally the
        <computeroutput>ulimit</computeroutput> is set low or even at
        zero, since most non-developers have little use for a core
        dump file.  However the core dump remains the single most
        useful way to debug an unexpected situation in a postmortem
        fashion.</para>
      </section>
    </section>

    <section xml:id="extra_sections">
      <info>
	<title>Custom sections</title>
      </info>

      <para>For the most part, organisation of code, data and symbols
      is something a programmer can leave up the toolchain defaults.
      However, there are times when it makes sense to extend or
      customise sections and their contents.  One common example of
      this is with Linux kernel <emphasis>modules</emphasis> which are
      used to dynamically load drivers and other features into the
      running kernel.  Because these modules are not portable, in so
      much as they only work with one fixed kernel build version, the
      interface between modules and the kernel can be flexible and is
      not bound to particular standards.  This means the methods of
      storing things like license information, authorship,
      dependencies and paramaters for the moudule can be uniquely and
      wholly defined by the kernel.</para>

      <para>The <computeroutput>modinfo</computeroutput> tool can
      inspect this information within a module and present it to the
      user.  Below we use the example of the <command>FUSE</command>
      Linux kernel module, which allows user-space libraries to
      provide file-system implementations to the kernel.</para>

      <example xml:id="modinfo">
	<info>
	  <title>Example of <computeroutput>modinfo</computeroutput>
	  output</title>
	</info>
	<programlisting linenumbering="numbered"><xi:include href="code/modules.txt" parse="text"/></programlisting>
      </example>

      <para>As you can see above,
      <computeroutput>modinfo</computeroutput> is parsing the
      <computeroutput>.modinfo</computeroutput> section embedded
      within the module file to present the details of the module.
      <xref linkend="modinfo_sections" /> shows how one field, the
      "author" is put into the module.  The code mostly comes from
      <computeroutput>include/linux/module.h</computeroutput>.
      </para>

      <example xml:id="modinfo_sections">
	<info>
	  <title>Putting module info into sections</title>
	</info>
	<programlisting linenumbering="numbered" language="c"><xi:include href="code/modinfo.c" parse="text"/></programlisting>
      </example>

      <para>At first, this looks like a macro nightmare, but it can be
      unravelled step by step.  Starting at the bottom, we see that
      <computeroutput>MODULE_AUTHOR</computeroutput> is a wrapper
      around the more generic
      <computeroutput>__MODULE_INFO</computeroutput> macro, which is
      where most of the magic happens.  There, we can see that we are
      building up a <computeroutput>static const char
      []</computeroutput> variable to hold the string
      <computeroutput>"author=Your Name
      &lt;your@name.com&gt;"</computeroutput>.  The interesting thing
      to note is that the variable has an extra parameter
      <computeroutput>__attribute__((section(".modinfo")))</computeroutput>
      which is telling the compiler to not put this in the
      <computeroutput>data</computeroutput> section with all the other
      variables, but to stash it in its own ELF section called
      <computeroutput>.modinfo</computeroutput>.  The other parameters
      stop the variable being optimised away because it looks unused
      and to ensure we pack the variables in next to each other by
      specifying the alignment.</para>

      <para>There is extensive use of
      <emphasis>stringification</emphasis> macros, which are rather
      arcane tricks used within the C pre-processor to ensure that
      strings and definitions can live together.  The only other
      trick is the use of the
      <computeroutput>__COUNTER__</computeroutput> special define
      provided by <command>gcc</command>, which provides a unique,
      incrementing value each time it is called; this allows
      multiple <computeroutput>MODULE_AUTHOR</computeroutput> calls
      to in the one file and not end up with the same variable
      name.</para>

      <para>We can inspect the symbols placed in the final
      module to see the end result:</para>

      <example xml:id="module-symbols">
        <info>
          <title>Module symbols in
          <computeroutput>.modinfo</computeroutput> sections</title>
        </info>
        <programlisting linenumbering="numbered"><xi:include href="code/module-symbols.txt" parse="text"/></programlisting>
        </example>

      </section>

      <section>
        <info>
          <title>Linker Scripts</title>
        </info>

       <para>
         In <xref linkend="section" /> we described how sections make
         up segments in the final output.  It is the job of the linker
         to build these sections into segments; to achieve this it
         uses a <emphasis>linker script</emphasis> which describes
         where segments start, what sections go into them and various
         other parameters.  </para>

       <para><xref linkend="linker-script" /> shows an extract of the
       default linker script, which the linker will show when given
       its verbose flag via specifying
       <computeroutput>-Wl,--verbose</computeroutput> to
       <application>gcc</application>.  The default script is built-in
       to the linker and is based on the standard API definitions to
       create working user-space programs for the building
       platform.</para>

       <example xml:id="linker-script">
         <info>
           <title>The default linker script</title>
         </info>
         <programlisting linenumbering="numbered"><xi:include href="code/linker-script.txt" parse="text"/></programlisting>
       </example>

       <para>You can roughly see how the linker script specifies
       things like starting locations and what sections to group into
       various segments.  In the same way
       <computeroutput>-Wl</computeroutput> is used to pass the
       <computeroutput>--verbose</computeroutput> to the linker via
       <application>gcc</application>, customised linker scripts can
       be provided by flags.  Regular user-space developers are
       unlikely to need to override the default linker script.
       However, often very customised applications such as kernel
       builds require customised linker scripts.
       </para>

      </section>
    </section>

    <section xml:id="abi">
    <info>
      <title>ABIs</title>
    </info>
    <para>An ABI is a term you will hear a lot about when working with
    systems programming.  We have talked extensively about
    <emphasis>API</emphasis>, which are interfaces the programmer sees
    to your code.</para>
    <para>ABI's refer to lower level interfaces which the compiler,
    operating system and, to some extent, processor, must agree on to
    communicate together.  Below we introduce a number of concepts
    which are important to understanding ABI considerations.</para>
    <section>
      <info>
        <title>Byte Order</title>
      </info>
      <para>Endianess</para>
    </section>
    <section>
      <info>
        <title>Calling Conventions</title>
      </info>
      <section>
        <info>
          <title>Passing parameters</title>
        </info>
        <para>registers or stack?</para>
      </section>
      <section>
        <info>
          <title>Function Descriptors</title>
        </info>
        <para>On many architectures you must call a function through a
	<emphasis>function descriptor</emphasis>, rather than
	directly.</para>
        <para>For example, on IA64 a function descriptor consists of
	two components; the address of the function (that being a 64
	bit, or 8 byte value) and the address of the <emphasis>global
	pointer</emphasis> (gp).  The ABI specifies that r1 should
	always contain the gp value for a function.  This means that
	when you call a function, it is the
	<computeroutput>callers</computeroutput> job to save their gp
	value, set r1 to be the new value (from the function
	descriptor) and <computeroutput>then</computeroutput> call the
	function.</para>
        <para>This may seem like a strange way to do things, but it
	has very useful practical implications as you will see in the
	next chapter about global offset tables.  On IA64 an
	<computeroutput>add</computeroutput> instruction can only take
	a maximum 22 bit <emphasis>immediate
	value</emphasis><footnote><para>Technically this is because of
	the way IA64 bundles instructions.  Three instructions are put
	into each bundle, and there is only enough room to keep a 22
	bit value to keep the bundle together.</para></footnote>.  An
	immediate value is one that is specified directly, rather than
	in a register (e.g. in <computeroutput>add r1 +
	100</computeroutput> 100 is the immediate value).</para>
        <para>You might recognise 22 bits as being able to represent
	4194304 bytes, or 4MB.  Thus each function can directly offset
	into an area of memory 4MB big without having to take the
	penalty of loading any values into a register.  If the
	compiler, linker and loader all agree on what the global
	pointer is pointing to (as specified in the ABI) performance
	can be improved by less loading.</para>
      </section>
    </section>
  </section>
  <section xml:id="starting_a_process">
    <info>
      <title>Starting a process</title>
    </info>
    <para>We mentioned before that simply saying the program starts
    with the <computeroutput>main()</computeroutput> function is not
    quite true.  Below we examine what happens to a typical dynamically
    linked program when it is loaded and run (statically linked
    programs are similar but different XXX should we go into
    this?).</para>
    <para>Firstly, in response to an
    <computeroutput>exec</computeroutput> system call the kernel
    allocates the structures for a new process and reads the ELF file
    specified from disk.</para>
    <para>We mentioned that ELF has a program interpreter field,
    <computeroutput>PT_INTERP</computeroutput>, which can be set to
    'interpret' the program.  For dynamically linked applications that
    interpreter is the dynamic linker, namely
    <application>ld.so</application>, which allows some of the linking
    process to be done on the fly before the program starts.</para>
    <para>In this case, the kernel <emphasis>also</emphasis> reads in
    the dynamic linker code, and starts the program from the entry
    point address as specified by it.  We examine the role of the
    dynamic linker in depth in the next chapter, but suffice to say it
    does some setup like loading any libraries required by the
    application (as specified in the dynamic section of the binary)
    and then starts execution of the program binary at its entry
    point address (i.e. the <computeroutput>_init</computeroutput>
    function).</para>
    <section xml:id="auxv">
      <info>
        <title>Kernel communication to programs</title>
      </info>
      <para>The kernel needs to communicate some things to programs
      when they start up; namely the arguments to the program, the
      current environment variables and a special structure called the
      <computeroutput>Auxiliary Vector</computeroutput> or
      <computeroutput>auxv</computeroutput> (you can request the the
      dynamic linker show you some debugging output of the
      <computeroutput>auxv</computeroutput> by specifying the
      environment value
      <computeroutput>LD_SHOW_AUXV=1</computeroutput>).</para>
      <para>The arguments and environment at fairly straight forward,
      and the various incarnations of the
      <computeroutput>exec</computeroutput> system call allow you to
      specify these for the program.</para>
      <para>The kernel communicates this by putting all the required
      information on the stack for the newly created program to pick
      up.  Thus when the program starts it can use its stack pointer
      to find the all the startup information required.</para>
      <para>The auxiliary vector is a special structure that is for
      passing information directly from the kernel to the newly
      running program.  It contains system specific information that
      may be required, such as the default size of a virtual memory
      page on the system or <emphasis>hardware
      capabilities</emphasis>; that is specific features that the
      kernel has identified the underlying hardware has that userspace
      programs can take advantage of.</para>
      <section xml:id="kernel_library">
        <info>
          <title>Kernel Library</title>
        </info>
        <para>We mentioned previously that system calls are slow, and
	modern systems have mechanisms to avoid the overheads of
	calling a trap to the processor.</para>
        <para>In Linux, this is implemented by a neat trick between
	the dynamic loader and the kernel, all communicated with the
	AUXV structure.  The kernel actually adds a small shared
	library into the address space of every newly created process
	which contains a function that makes system calls for you.
	The beauty of this system is that if the underlying hardware
	supports a fast system call mechanism the kernel (being the
	creator of the library) can use it, otherwise it can use the
	old scheme of generating a trap.  This library is named
	<computeroutput>linux-gate.so.1</computeroutput>, so called
	because it is a <emphasis>gateway</emphasis> to the inner
	workings of the kernel.</para>
        <para>When the kernel starts the dynamic linker it adds an
	entry to the auxv called
	<computeroutput>AT_SYSINFO_EHDR</computeroutput>, which is the
	address in memory that the special kernel library lives in.
	When the dynamic linker starts it can look for the
	<computeroutput>AT_SYSINFO_EHDR</computeroutput> pointer, and
	if found load that library for the program.  The program has
	no idea this library exists; this is a private arrangement
	between the dynamic linker and the kernel.</para>
        <para>We mentioned that programmers make system calls
	indirectly through calling functions in the system libraries,
	namely <application>libc</application>.
	<application>libc</application> can check to see if the
	special kernel binary is loaded, and if so use the functions
	within that to make system calls.  As we mentioned, if the
	kernel determines the hardware is capable, this will use the
	fast system call method.</para>
      </section>
    </section>
    <section xml:id="startup">
      <info>
        <title>Starting the program</title>
      </info>
      <para>Once the kernel has loaded the interpreter it passes it to
      the entry point as given in the interpreter file (note will not
      examine how the dynamic linker starts at this stage; see <xref linkend="chapter08"/> for a full discussion of dynamic
      linking).  The dynamic linker will jump to the entry point
      address as given in the ELF binary.</para>
      <example xml:id="program-startup">
        <info>
          <title>Disassembley of program startup</title>
        </info>
        <programlisting linenumbering="numbered"><xi:include href="code/startup.txt" parse="text"/></programlisting>
      </example>
      <para>Above we investigate the very simplest program.  Using
      <application>readelf</application> we can see that the entry
      point is the <computeroutput>_start</computeroutput> function in
      the binary.  At this point we can see in the disassembley some
      values are pushed onto the stack.  The first value,
      <computeroutput>0x8048400</computeroutput> is the
      <computeroutput>__libc_csu_fini</computeroutput> function;
      <computeroutput>0x8048390</computeroutput> is the
      <computeroutput>__libc_csu_init</computeroutput> and then
      finally <computeroutput>0x8048368</computeroutput>, the
      <computeroutput>main()</computeroutput> function.  After this
      the value <computeroutput>__libc_start_main</computeroutput>
      function is called.</para>
      <para><computeroutput>__libc_start_main</computeroutput> is
      defined in the glibc sources
      <computeroutput>sysdeps/generic/libc-start.c</computeroutput>.
      The file function is quite complicated and hidden between a
      large number of defines, as it needs to be portable across the
      very wide number of systems and architectures that glibc can run
      on.  It does a number of specific things related to setting up
      the C library which the average programmer does not need to
      worry about.  The next point where the library calls back into
      the program is to handle <computeroutput>init</computeroutput>
      code.</para>
      <para><computeroutput>init</computeroutput> and
      <computeroutput>fini</computeroutput> are two special concepts
      that call parts of code in shared libraries that may need to be
      called before the library starts or if the library is unloaded
      respectively.  You can see how this might be useful for library
      programmers to setup variables when the library is started, or
      to clean up at the end.  Originally the functions
      <computeroutput>_init</computeroutput> and
      <computeroutput>_fini</computeroutput> were looked for in the
      library; however this became somewhat limiting as everything was
      required to be in these functions.  Below we will examine just
      how the
      <computeroutput>init</computeroutput>/<computeroutput>fini</computeroutput>
      process works.</para>
      <para>At this stage we can see that the
      <computeroutput>__libc_start_main</computeroutput> function will
      receive quite a few input paramaters on the stack.  Firstly it
      will have access to the program arguments, environment variables
      and auxiliary vector from the kernel.  Then the initalization
      function will have pushed onto the stack addresses for functions
      to handle <computeroutput>init</computeroutput>,
      <computeroutput>fini</computeroutput>, and finally the address
      of the main function itself.</para>
      <para>We need some way to indicate in the source code that a
      function should be called by
      <computeroutput>init</computeroutput> or
      <computeroutput>fini</computeroutput>.  With
      <application>gcc</application> we use
      <emphasis>attributes</emphasis> to label two functions as
      <emphasis>constructors</emphasis> and
      <emphasis>destructors</emphasis> in our main program.  These
      terms are more commonly used with object oriented languages to
      describe object life cycles.</para>
      <example xml:id="constructor-destructor">
        <info>
          <title>Constructors and Destructors</title>
        </info>
        <programlisting linenumbering="numbered"><xi:include href="code/construct-destruct.txt" parse="text"/></programlisting>
      </example>
      <para>The last value pushed onto the stack for the
      <computeroutput>__libc_start_main</computeroutput> was the
      initialisation function
      <computeroutput>__libc_csu_init</computeroutput>.  If we follow
      the call chain through from
      <computeroutput>__libc_csu_init</computeroutput> we can see it
      does some setup and then calls the
      <computeroutput>_init</computeroutput> function in the
      executable.  The <computeroutput>_init</computeroutput> function
      eventually calls a function called
      <computeroutput>__do_global_ctors_aux</computeroutput>.  Looking
      at the disassembley of this function we can see that it appears
      to start at address <computeroutput>0x804952c</computeroutput>
      and loop along, reading an value and calling it.  We can see
      that this starting address is in the
      <computeroutput>.ctors</computeroutput> section of the file; if
      we have a look inside this we see that it contains the first
      value <computeroutput>-1</computeroutput>, a function address
      (in big endian format) and the value zero.</para>
      <para>The address in big endian format is
      <computeroutput>0x08048398</computeroutput>, or the address of
      <computeroutput>program_init</computeroutput> function!  So the
      format of the <computeroutput>.ctors</computeroutput> section is
      firstly a -1, and then the address of functions to be called on
      initialisation, and finally a zero to indicate the list is
      complete.  Each entry will be called (in this case we only have
      the one function).</para>
      <para>Once <computeroutput>__libc_start_main</computeroutput>
      has completed with the <computeroutput>_init</computeroutput>
      call it <emphasis>finally</emphasis> calls the
      <computeroutput>main()</computeroutput> function!  Remember that
      it had the stack setup initially with the arguments and
      environment pointers from the kernel; this is how main gets its
      <computeroutput>argc, argv[], envp[]</computeroutput> arguments.
      The process now runs and the setup phase is complete.</para>
      <para>A similar process is enacted with the
      <computeroutput>.dtors</computeroutput> for destructors when the
      program exits.
      <computeroutput>__libc_start_main</computeroutput> calls these
      when the <computeroutput>main()</computeroutput> function
      completes.</para>
      <para>As you can see, a lot is done before the program gets to
      start, and even a little after you think it is finished!</para>
    </section>
  </section>

</chapter>
